{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this whole workbook will give you the full 2019 dataset. But it might take weeks for a full run ;) <br>\n",
    "Try reducing the number of datetime query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from datetime import date, timedelta\n",
    "from shapely import wkt\n",
    "from shapely.ops import nearest_points\n",
    "import geopandas as gpd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating list of dates 2019\n",
    "sdate = date(2019,1,1)\n",
    "#edate = date(2019,1,2)\n",
    "edate = date(2020,1,1)  \n",
    "dates_2019 = pd.date_range(sdate,edate-timedelta(days=1),freq='d')\n",
    "dates_2019 = [str(x)[:10] for x in dates_2019]\n",
    "\n",
    "# Generating list of hours 00 to 23\n",
    "#military_time = ['00','01']\n",
    "military_time = np.arange(0,24,1)\n",
    "military_time = [('0'+str(x))[-2:] for x in military_time]\n",
    "\n",
    "# 15-min interval\n",
    "#minutes = ['00']\n",
    "minutes = ['00', '15','30', '45']\n",
    "\n",
    "all_queries = []\n",
    "for i in dates_2019:\n",
    "    for hour in military_time:\n",
    "        for minute in minutes:\n",
    "            all_queries.append(i + 'T' + hour + \":\" + minute + \":00\")\n",
    "\n",
    "# eg of query: \"2019-01-01T20:00:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data(query:str):\n",
    "    '''Returns dictionary of JSON objects for weather data given a datetime string\n",
    "    Each entry in the dictionary is the JSON response for each of the API Endpoints of\n",
    "     [\"air-temperature\",\"rainfall\",\"relative-humidity\"]    \n",
    "    '''\n",
    "    data_sets = [\"air-temperature\",\"rainfall\",\"relative-humidity\"]\n",
    "    results={}\n",
    "    for measure in data_sets:\n",
    "        URL = \"https://api.data.gov.sg/v1/environment/\"+measure\n",
    "        params={'date_time':query}\n",
    "        r=requests.get(URL,params=params)\n",
    "        results[measure]=r.json()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying each timestamp and writing it to individual dataset (for humidity, rainfall, temp)\n",
    "df_temp = pd.DataFrame()\n",
    "df_rain = pd.DataFrame()\n",
    "df_humid = pd.DataFrame()\n",
    "\n",
    "df_temp_stn = pd.DataFrame()\n",
    "df_rain_stn = pd.DataFrame()\n",
    "df_humid_stn = pd.DataFrame()\n",
    "\n",
    "for query in all_queries:\n",
    "    # Query data\n",
    "    weather_data = get_weather_data(query)\n",
    "################################            \n",
    "    # For item df (temp)\n",
    "    temp_stn = np.array([i['station_id'] for i in weather_data['air-temperature']['items'][0]['readings']])\n",
    "    temp_val = np.array([i['value'] for i in weather_data['air-temperature']['items'][0]['readings']])\n",
    "    itr_temp = pd.DataFrame({'timestamp': [query for xx in range(len(temp_stn))],\n",
    "                             'station_id': temp_stn, 'value': temp_val})\n",
    "    df_temp = pd.concat([df_temp, itr_temp]) # concat to item df\n",
    "\n",
    "    # For metadata df (temp)\n",
    "    temp_stn = np.array([i['id'] for i in weather_data['air-temperature']['metadata']['stations']]) # id\n",
    "    temp_lat = np.array([i['location']['latitude'] for i in weather_data['air-temperature']['metadata']['stations']]) # lat\n",
    "    temp_lon = np.array([i['location']['longitude'] for i in weather_data['air-temperature']['metadata']['stations']]) # lon\n",
    "    itr_temp_meta = pd.DataFrame({'timestamp': [query for xx in range(len(temp_stn))],\n",
    "                             'station_id': temp_stn, 'latitude': temp_lat, 'longitude': temp_lon})\n",
    "    df_temp_stn = pd.concat([df_temp_stn, itr_temp_meta]) # concat to meta to df\n",
    "################################     \n",
    "    # For item df (rain)\n",
    "    rain_stn = np.array([i['station_id'] for i in weather_data['rainfall']['items'][0]['readings']])\n",
    "    rain_val = np.array([i['value'] for i in weather_data['rainfall']['items'][0]['readings']])\n",
    "    itr_rain = pd.DataFrame({'timestamp': [query for xx in range(len(rain_stn))],\n",
    "                             'station_id': rain_stn, 'value': rain_val})\n",
    "    df_rain = pd.concat([df_rain, itr_rain]) # concat to item df\n",
    "\n",
    "    # For metadata df (temp)\n",
    "    rain_stn = np.array([i['id'] for i in weather_data['rainfall']['metadata']['stations']]) # id\n",
    "    rain_lat = np.array([i['location']['latitude'] for i in weather_data['rainfall']['metadata']['stations']]) # lat\n",
    "    rain_lon = np.array([i['location']['longitude'] for i in weather_data['rainfall']['metadata']['stations']]) # lon\n",
    "    itr_rain_meta = pd.DataFrame({'timestamp': [query for xx in range(len(rain_stn))],\n",
    "                             'station_id': rain_stn, 'latitude': rain_lat, 'longitude': rain_lon})\n",
    "    df_rain_stn = pd.concat([df_rain_stn, itr_rain_meta]) # concat to meta to df\n",
    "################################    \n",
    "    # For item df (humid)\n",
    "    humid_stn = np.array([i['station_id'] for i in weather_data['relative-humidity']['items'][0]['readings']])\n",
    "    humid_val = np.array([i['value'] for i in weather_data['relative-humidity']['items'][0]['readings']])\n",
    "    itr_humid = pd.DataFrame({'timestamp': [query for xx in range(len(humid_stn))],\n",
    "                             'station_id': humid_stn, 'value': humid_val})\n",
    "    df_humid = pd.concat([df_humid, itr_humid]) # concat to item df\n",
    "\n",
    "    # For metadata df (humid)\n",
    "    humid_stn = np.array([i['id'] for i in weather_data['relative-humidity']['metadata']['stations']]) # id\n",
    "    humid_lat = np.array([i['location']['latitude'] for i in weather_data['relative-humidity']['metadata']['stations']]) # lat\n",
    "    humid_lon = np.array([i['location']['longitude'] for i in weather_data['relative-humidity']['metadata']['stations']]) # lon\n",
    "    itr_humid_meta = pd.DataFrame({'timestamp': [query for xx in range(len(humid_stn))],\n",
    "                             'station_id': humid_stn, 'latitude': humid_lat, 'longitude': humid_lon})\n",
    "    df_humid_stn = pd.concat([df_humid_stn, itr_humid_meta]) # concat to meta to df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SG grid shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_num</th>\n",
       "      <th>geometry</th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>POLYGON ((103.60000 1.47500, 103.61000 1.47500...</td>\n",
       "      <td>POINT (103.60500 1.47006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON ((103.61000 1.47500, 103.62000 1.47500...</td>\n",
       "      <td>POINT (103.61500 1.47006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>POLYGON ((103.62000 1.47500, 103.63000 1.47500...</td>\n",
       "      <td>POINT (103.62500 1.47006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>POLYGON ((103.63000 1.47500, 103.64000 1.47500...</td>\n",
       "      <td>POINT (103.63500 1.47006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>POLYGON ((103.64000 1.47500, 103.65000 1.47500...</td>\n",
       "      <td>POINT (103.64500 1.47006)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_num                                           geometry  \\\n",
       "0       1.0  POLYGON ((103.60000 1.47500, 103.61000 1.47500...   \n",
       "1       2.0  POLYGON ((103.61000 1.47500, 103.62000 1.47500...   \n",
       "2       3.0  POLYGON ((103.62000 1.47500, 103.63000 1.47500...   \n",
       "3       4.0  POLYGON ((103.63000 1.47500, 103.64000 1.47500...   \n",
       "4       5.0  POLYGON ((103.64000 1.47500, 103.65000 1.47500...   \n",
       "\n",
       "                    centroid  \n",
       "0  POINT (103.60500 1.47006)  \n",
       "1  POINT (103.61500 1.47006)  \n",
       "2  POINT (103.62500 1.47006)  \n",
       "3  POINT (103.63500 1.47006)  \n",
       "4  POINT (103.64500 1.47006)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read SG grid shape file - 47*27\n",
    "grids = gpd.read_file('SG_grid/SG_grids.shp')\n",
    "grids['centroid'] = grids['geometry'].apply(lambda x: x.centroid) # grids get centroid\n",
    "grids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each timestamp, match weather data and num avail taxi to each grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gpd(df):\n",
    "    coord = list(zip(df['longitude'], df['latitude']))\n",
    "    iterim = df\n",
    "    iterim[\"Coordinates\"] = [f'POINT({str(i[0])} {str(i[1])})' for i in coord]\n",
    "    \n",
    "    iterim['geometry'] = iterim.Coordinates.apply(wkt.loads)\n",
    "    gdf_stn = gpd.GeoDataFrame(iterim, geometry='geometry')\n",
    "    gdf_stn.drop('Coordinates', inplace=True, axis=1)\n",
    "    gdf_stn.reset_index(inplace=True)\n",
    "    \n",
    "    return gdf_stn\n",
    "\n",
    "def near(point, gdf, pts):\n",
    "    # find the nearest point and return the corresponding Place value\n",
    "    nearest = gdf.geometry == nearest_points(point, pts)[1]\n",
    "    return gdf[nearest].station_id.to_numpy()[0]\n",
    "\n",
    "## Get taxi avail data\n",
    "def get_taxi_data(query:str):\n",
    "    '''Returns the coordinates of all taxis via the LTA API endpoint for a given datetime string\n",
    "    '''\n",
    "    URL = \"https://api.data.gov.sg/v1/transport/taxi-availability\"\n",
    "    params={'date_time':query}\n",
    "    r=requests.get(URL,params=params)\n",
    "    return r.json()\n",
    "\n",
    "def taxi_convert_gpd(taxi_data):\n",
    "    taxi_list = taxi_data['features'][0]['geometry'][\"coordinates\"]\n",
    "    df2 = pd.DataFrame({'timestamp': [query for x in range(len(taxi_list))]})\n",
    "    df2[\"Coordinates\"] = [f'POINT({str(i[0])} {str(i[1])})' for i in taxi_list]\n",
    "\n",
    "    df2['geometry'] = df2.Coordinates.apply(wkt.loads)\n",
    "    gdf2 = gpd.GeoDataFrame(df2, geometry='geometry')\n",
    "    gdf2.drop('Coordinates', inplace=True, axis=1)\n",
    "    gdf2.reset_index(inplace=True)\n",
    "    return gdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\csong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# For each timestamp, get weather data for each grid\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for timestamp in all_queries:\n",
    "    ## GET WEATHER DATA\n",
    "    # subset for just 1 timestamp (FOR RAIN)\n",
    "    ss_rain_val = df_rain[df_rain[\"timestamp\"] == timestamp]\n",
    "    ss_rain_stn = df_rain_stn[df_rain_stn['timestamp'] == timestamp]\n",
    "    \n",
    "    gdf_rain_stn = convert_gpd(ss_rain_stn)\n",
    "    ## Getting nearest rain station for each grid\n",
    "    pts3 = gdf_rain_stn.geometry.unary_union\n",
    "    grids_final = copy.deepcopy(grids)\n",
    "    grids_final['station_id'] = grids_final.apply(lambda row: near(row.geometry, gdf_rain_stn, pts3), axis=1)\n",
    "    grids_final = grids_final.merge(ss_rain_val, on = ['station_id'], how='inner')\n",
    "    grids_final.rename(columns = {'value':'rainfall'}, inplace = True)\n",
    "    grids_final = grids_final.drop(['station_id', 'timestamp'], axis=1)\n",
    "    \n",
    "    #############################################\n",
    "    # subset for just 1 timestamp (FOR TEMP)\n",
    "    ss_temp_val = df_temp[df_temp[\"timestamp\"] == timestamp]\n",
    "    ss_temp_stn = df_temp_stn[df_temp_stn['timestamp'] == timestamp]\n",
    "    \n",
    "    gdf_temp_stn = convert_gpd(ss_temp_stn)\n",
    "    ## Getting nearest rain station for each grid\n",
    "    pts3 = gdf_temp_stn.geometry.unary_union\n",
    "    grids_final['station_id'] = grids_final.apply(lambda row: near(row.geometry, gdf_temp_stn, pts3), axis=1)\n",
    "    grids_final = grids_final.merge(ss_temp_val, on = ['station_id'], how='inner')\n",
    "    grids_final.rename(columns = {'value':'air_temp'}, inplace = True)\n",
    "    grids_final = grids_final.drop(['station_id', 'timestamp'], axis=1)\n",
    "    \n",
    "    #############################################\n",
    "    # subset for just 1 timestamp (FOR HUMID)\n",
    "    ss_humid_val = df_humid[df_humid[\"timestamp\"] == timestamp]\n",
    "    ss_humid_stn = df_humid_stn[df_humid_stn['timestamp'] == timestamp]\n",
    "    \n",
    "    gdf_humid_stn = convert_gpd(ss_humid_stn)\n",
    "    ## Getting nearest rain station for each grid\n",
    "    pts3 = gdf_humid_stn.geometry.unary_union\n",
    "    grids_final['station_id'] = grids_final.apply(lambda row: near(row.geometry, gdf_humid_stn, pts3), axis=1)\n",
    "    grids_final = grids_final.merge(ss_humid_val, on = ['station_id'], how='inner')\n",
    "    grids_final.rename(columns = {'value':'humidity'}, inplace = True)\n",
    "    grids_final = grids_final.drop(['station_id'], axis=1)\n",
    "    \n",
    "    \n",
    "    ## GET TAXI AVAIL DATA\n",
    "    taxi_data=get_taxi_data(query=timestamp)\n",
    "    taxi_gdf = taxi_convert_gpd(taxi_data)\n",
    "    ## Count how many taxis in each grid \n",
    "    grids_final[\"num_taxi\"] = 0\n",
    "    for pt in range(len(taxi_gdf)): # for each taxi\n",
    "        geom = taxi_gdf['geometry'][pt]\n",
    "        for plg in range(len(grids_final)):\n",
    "            poly = grids_final['geometry'][plg]\n",
    "            if poly.contains(geom):\n",
    "                grids_final.loc[plg, \"num_taxi\"] += 1\n",
    "                break\n",
    "                \n",
    "    # APPEND DATA FROM THIS TIMESTAMP TO final_df\n",
    "    final_df = pd.concat([final_df, grids_final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_num</th>\n",
       "      <th>geometry</th>\n",
       "      <th>centroid</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>num_taxi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>POLYGON ((103.60000 1.47500, 103.61000 1.47500...</td>\n",
       "      <td>POINT (103.60500 1.47006)</td>\n",
       "      <td>0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>2019-01-01T00:00:00</td>\n",
       "      <td>88.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON ((103.61000 1.47500, 103.62000 1.47500...</td>\n",
       "      <td>POINT (103.61500 1.47006)</td>\n",
       "      <td>0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>2019-01-01T00:00:00</td>\n",
       "      <td>88.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>POLYGON ((103.60000 1.46511, 103.61000 1.46511...</td>\n",
       "      <td>POINT (103.60500 1.46017)</td>\n",
       "      <td>0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>2019-01-01T00:00:00</td>\n",
       "      <td>88.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>POLYGON ((103.61000 1.46511, 103.62000 1.46511...</td>\n",
       "      <td>POINT (103.61500 1.46017)</td>\n",
       "      <td>0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>2019-01-01T00:00:00</td>\n",
       "      <td>88.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>POLYGON ((103.62000 1.46511, 103.63000 1.46511...</td>\n",
       "      <td>POINT (103.62500 1.46017)</td>\n",
       "      <td>0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>2019-01-01T00:00:00</td>\n",
       "      <td>88.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>POLYGON ((103.90000 1.21789, 103.91000 1.21789...</td>\n",
       "      <td>POINT (103.90500 1.21294)</td>\n",
       "      <td>0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>2019-01-01T01:00:00</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1211</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>POLYGON ((103.91000 1.21789, 103.92000 1.21789...</td>\n",
       "      <td>POINT (103.91500 1.21294)</td>\n",
       "      <td>0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>2019-01-01T01:00:00</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1212</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>POLYGON ((103.92000 1.21789, 103.93000 1.21789...</td>\n",
       "      <td>POINT (103.92500 1.21294)</td>\n",
       "      <td>0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>2019-01-01T01:00:00</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1213</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>POLYGON ((103.93000 1.21789, 103.94000 1.21789...</td>\n",
       "      <td>POINT (103.93500 1.21294)</td>\n",
       "      <td>0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>2019-01-01T01:00:00</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1214</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>POLYGON ((103.94000 1.21789, 103.95000 1.21789...</td>\n",
       "      <td>POINT (103.94500 1.21294)</td>\n",
       "      <td>0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>2019-01-01T01:00:00</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2430 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      grid_num                                           geometry  \\\n",
       "0          1.0  POLYGON ((103.60000 1.47500, 103.61000 1.47500...   \n",
       "1          2.0  POLYGON ((103.61000 1.47500, 103.62000 1.47500...   \n",
       "2         46.0  POLYGON ((103.60000 1.46511, 103.61000 1.46511...   \n",
       "3         47.0  POLYGON ((103.61000 1.46511, 103.62000 1.46511...   \n",
       "4         48.0  POLYGON ((103.62000 1.46511, 103.63000 1.46511...   \n",
       "...        ...                                                ...   \n",
       "1210    1201.0  POLYGON ((103.90000 1.21789, 103.91000 1.21789...   \n",
       "1211    1202.0  POLYGON ((103.91000 1.21789, 103.92000 1.21789...   \n",
       "1212    1203.0  POLYGON ((103.92000 1.21789, 103.93000 1.21789...   \n",
       "1213    1204.0  POLYGON ((103.93000 1.21789, 103.94000 1.21789...   \n",
       "1214    1205.0  POLYGON ((103.94000 1.21789, 103.95000 1.21789...   \n",
       "\n",
       "                       centroid  rainfall  air_temp            timestamp  \\\n",
       "0     POINT (103.60500 1.47006)         0      25.3  2019-01-01T00:00:00   \n",
       "1     POINT (103.61500 1.47006)         0      25.3  2019-01-01T00:00:00   \n",
       "2     POINT (103.60500 1.46017)         0      25.3  2019-01-01T00:00:00   \n",
       "3     POINT (103.61500 1.46017)         0      25.3  2019-01-01T00:00:00   \n",
       "4     POINT (103.62500 1.46017)         0      25.3  2019-01-01T00:00:00   \n",
       "...                         ...       ...       ...                  ...   \n",
       "1210  POINT (103.90500 1.21294)         0      26.9  2019-01-01T01:00:00   \n",
       "1211  POINT (103.91500 1.21294)         0      26.9  2019-01-01T01:00:00   \n",
       "1212  POINT (103.92500 1.21294)         0      26.9  2019-01-01T01:00:00   \n",
       "1213  POINT (103.93500 1.21294)         0      26.9  2019-01-01T01:00:00   \n",
       "1214  POINT (103.94500 1.21294)         0      26.9  2019-01-01T01:00:00   \n",
       "\n",
       "      humidity  num_taxi  \n",
       "0         88.6         0  \n",
       "1         88.6         0  \n",
       "2         88.6         0  \n",
       "3         88.6         0  \n",
       "4         88.6         0  \n",
       "...        ...       ...  \n",
       "1210      87.9         0  \n",
       "1211      87.9         0  \n",
       "1212      87.9         0  \n",
       "1213      87.9         0  \n",
       "1214      87.9         0  \n",
       "\n",
       "[2430 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
