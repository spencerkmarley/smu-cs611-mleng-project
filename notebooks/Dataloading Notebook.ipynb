{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd24cbd1-f991-4b66-afd0-046095f5e79a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Google Cloud Storage Access Notebook\n",
    "\n",
    "This notebook contains code for the prototyping of loading to bigquery via Google Cloud Storage.\n",
    "\n",
    "Important! Clone the [project repository](https://github.com/spencermarley/smu-cs611-mleng-project.git) in order to access the parsing functions.\n",
    "\n",
    "## Section 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34886aed-45a5-4ed2-a046-25edfeca87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import jsonParser\n",
    "from src import assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99af2d-0f08-4bc2-9321-955693e7e1a3",
   "metadata": {},
   "source": [
    "## Section 2 - Bucket Connection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c218c7-da9c-4baa-8d40-08594382d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'ml-eng-cs611-group-project'\n",
    "nea_bucket = 'ml-eng-cs611-group-project-nea'\n",
    "taxi_bucket = 'ml-eng-cs611-group-project-taxis'\n",
    "dataset_id='taxi_dataset'\n",
    "measure = 'rainfall'\n",
    "measures = ['rainfall','air-temperature','relative-humidity']\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project=project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053bd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_index(start_file:str,file_list:list):\n",
    "    '''Iteratively search from start of file list to find first occurence of end_file.\n",
    "    Args:\n",
    "        start_file (str): Search string. Can give a date of form YYYY-MM-DD to find first file at specific date, or filename to match specific file.\n",
    "        file_list (list): List of file paths from Google Cloud Storage.\n",
    "    Yields:\n",
    "        start_index (int): Index of last occurrence of search string.\n",
    "    '''\n",
    "    start_index=0\n",
    "\n",
    "    \n",
    "    file_re = re.compile(start_file)\n",
    "    \n",
    "    for file in file_list:\n",
    "        if file_re.findall(file):\n",
    "            start_index=file_list.index(file)\n",
    "            print(f\"Valid start file provided, starting batch loading at index {start_index}\")\n",
    "            break\n",
    "\n",
    "    return start_index\n",
    "\n",
    "def get_end_index(end_file:str,file_list:list):\n",
    "    '''Iteratively search from end of file list to find last occurence of end_file.\n",
    "    Args:\n",
    "        end_file (str): Search string. Can give a date of form YYYY-MM-DD to find last file at specific date, or filename to match specific file.\n",
    "        file_list (list): List of file paths from Google Cloud Storage.\n",
    "    Yields:\n",
    "        end_index (int): Index of last occurrence of search string.\n",
    "    '''\n",
    "    end_index=len(file_list)\n",
    "    \n",
    "    file_re = re.compile(end_file)\n",
    "    for file in file_list[::-1]:\n",
    "        if file_re.findall(file):\n",
    "            end_index=file_list.index(file)\n",
    "            print(f\"Valid end date provided, end batch loading at index {end_index}\")\n",
    "            break\n",
    "    \n",
    "    return end_index\n",
    "\n",
    "def load_nea_to_gbq(project:str,dataset_id:str,measure:str,filename:str,fs:None):\n",
    "    '''Load a single json \n",
    "    Args:\n",
    "        project:str:        \n",
    "        dataset_id:str:\n",
    "        measure:str:\n",
    "        filename:str:\n",
    "    '''\n",
    "    print(f\"Current processing {filename}\")\n",
    "    parser = jsonParser.jsonParser(fs)\n",
    "    \n",
    "    items = parser.get_items(filename,measure)\n",
    "    metadata = parser.get_metadata(filename,measure)\n",
    "\n",
    "    item_table = dataset_id+'.'+measure+'-items'\n",
    "    metadata_table = dataset_id+'.'+measure+'-metadata'\n",
    "\n",
    "    print(f\"Writing {measure} items to {item_table}\")\n",
    "    items.to_gbq(item_table,project,chunksize=None,if_exists='append')\n",
    "\n",
    "    print(f\"Writing {measure} metadata to {metadata_table}\")    \n",
    "    metadata.to_gbq(metadata_table,project,chunksize=None,if_exists='append')\n",
    "\n",
    "def load_taxi_to_gbq(project:str,dataset_id:str,filename:str,fs=None):\n",
    "    '''Load a single json \n",
    "    Args:\n",
    "        project:str:        \n",
    "        dataset_id:str:\n",
    "        measure:str:\n",
    "        filename:str:\n",
    "    '''\n",
    "    print(f\"Current processing {filename}\")\n",
    "    parser = jsonParser.jsonParser(fs)\n",
    "\n",
    "    taxi_data = parser.load_taxi_data(filename)\n",
    "\n",
    "    print(f\"Writing taxi data\")\n",
    "    taxi_data.to_gbq(dataset_id+'.'+'taxi-availability',project,chunksize=None,if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1204c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml-eng-cs611-group-project-nea/rainfall/2022-06-19T11-00-03.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nea_filenames = fs.glob('/'.join([nea_bucket,measure,\"*\"]))\n",
    "nea_filenames[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80cf1a90-b036-4a67-b7a8-f56378c03f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml-eng-cs611-group-project-taxis/taxis/2022-06-19T11-00-02.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_filenames = fs.glob('/'.join([taxi_bucket,'taxis',\"*\"]))\n",
    "taxi_filenames[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc623614-2bca-417a-b089-3c224dc32525",
   "metadata": {},
   "source": [
    "## Section 4 - Write to BigQuery\n",
    "\n",
    "We have created 6 tables in Bigquery:\n",
    "\n",
    "- `air-temperature-items`\n",
    "- `air-temperature-metadata`\n",
    "- `rainfall-items`\n",
    "- `rainfall-metadata`\n",
    "- `relative-humidity-items`\n",
    "- `relative-humidity-metadata`\n",
    "\n",
    "First, we write the corresponding measure metadata and items to the correct table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65dd644",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c8c4f-f444-401b-9120-3e46d117336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in measures:\n",
    "    print(f\"Writing items for {measure}\")\n",
    "    nea_data[measure]['items'].to_gbq(dataset_id+'.'+measure+'-items',project,chunksize=None,if_exists='append')\n",
    "    print(f\"Writing metadata for {measure}\")\n",
    "    nea_data[measure]['metadata'].to_gbq(dataset_id+'.'+measure+'-metadata',project,chunksize=None,if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2c892-48d8-4264-8ac2-48c18d21e105",
   "metadata": {},
   "source": [
    "Next, we write the taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ddbc6d-1ed4-49b1-8ee6-21ceeab7d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data.to_gbq(dataset_id+'.'+'taxi-availability',project,chunksize=None,if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd81be0-b9a3-41c3-8033-72cb614bdb33",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load most recent file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc795974-0e25-4a34-9137-de092d77d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path.append('smu-cs611-mleng-project')\n",
    "from src import jsonParser\n",
    "\n",
    "def load_nea_to_gbq(project:str,bucket:str,dataset_id:str,measure:str,filename:str):\n",
    "    '''Load a single json \n",
    "    Args:\n",
    "        project:str:\n",
    "        bucket\n",
    "        dataset_id\n",
    "        measure\n",
    "        filename\n",
    "    '''\n",
    "    fs = gcsfs.GCSFileSystem(project=project)\n",
    "    filenames = fs.glob('/'.join([bucket,measure,\"*\"]))\n",
    "    current_file=filenames[-1]\n",
    "    print(f\"Current processing {current_file}\")\n",
    "\n",
    "    parser = jsonParser.jsonParser(fs)\n",
    "    items = parser.get_items(current_file,measure)\n",
    "    metadata = parser.get_metadata(current_file,measure)\n",
    "\n",
    "    item_table = dataset_id+'.'+measure+'-items'\n",
    "    metadata_table = dataset_id+'.'+measure+'-metadata'\n",
    "\n",
    "    print(f\"Writing {measure} items to {item_table}\")\n",
    "    items.to_gbq(item_table,project,chunksize=None,if_exists='append')\n",
    "\n",
    "    print(f\"Writing {measure} metadata to {metadata_table}\")\n",
    "    metadata.to_gbq(metadata_table,project,chunksize=None,if_exists='append')\n",
    "\n",
    "project=params['project']\n",
    "bucket=params['bucket']\n",
    "dataset_id=params['dataset_id']\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Reads a single NEA JSON file to GBQ')    \n",
    "    parser.add_argument('--project','-p', default='ml-eng-cs611-group-project', type=str, help='GCP project name i.e. ml-eng-cs611-group-project')\n",
    "    parser.add_argument('--bucket','-b', default='ml-eng-cs611-group-project-nea', type=str, help='GCS bucket name i.e. ml-eng-cs611-group-project-nea')\n",
    "    parser.add_argument('--dataset_id','-d', default='taxi_dataset', type=str, help='GCS bucket name i.e. ml-eng-cs611-group-project-nea')\n",
    "    parser.add_argument('--measure','-m', type=str, help='NEA measure i.e. air-temperature,relative-humidity or rainfall')\n",
    "    parser.add_argument('--filename','-f', type=str, help='If provided, file to load')\n",
    "    parser.add_argument('--date','-d', type=str, help='YYYY-MM-DD format. If provided, load data up to this date')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    project = args.project\n",
    "    bucket = args.bucket\n",
    "    dataset_id = args.dataset_id\n",
    "    measure = args.measure\n",
    "    filename = args.filename\n",
    "    date = args.date\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b4760-4de5-4af9-98a7-962b3e41bfa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Section 4 - Assignment code\n",
    "\n",
    "First, get grid dataframe from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a70849-4ce3-458b-8c74-d569aab61d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = gpd.read_file('smu-cs611-mleng-project/Gridding/SG_grid/SG_grids.shp')\n",
    "grids['centroid'] = grids['geometry'].apply(lambda x: x.centroid) # grids get centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88d4e3c-23b7-4b54-aa3e-9da74c0ad270",
   "metadata": {},
   "source": [
    "Next, pass the grid and raw data into the Assignment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356db11-e225-4445-bc6c-69ee14dacc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_gdf = parser.load_taxi_gdf(taxi_filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e192a-fed4-495b-a76e-eb2e46534566",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigner = assignment.Assignment(grids=grids,nea_data=nea_data,taxi_data=taxi_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e736e-ea22-4e26-9e0d-a1c0ae27d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigner.nea_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0fae6-ef9c-448f-bf98-ab78be35aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigner.taxi_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5e824-3dfb-420c-bd5b-6833d4b26abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_df = assigner.merge_grids()\n",
    "assignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9b3fd-4d04-48ab-bd8f-b9f8becb08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb92d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.jsonParser import jsonParser\n",
    "from nea_load import load_nea_to_gbq\n",
    "from taxi_load import load_taxi_to_gbq\n",
    "import gcsfs\n",
    "import re\n",
    "\n",
    "project='ml-eng-cs611-group-project'\n",
    "dataset_id='taxi_dataset'\n",
    "measure = 'relative-humidity'\n",
    "filename = \"/home/ianchongweiming/smu-cs611-mleng-project/relative-humidity_2022-06-10T00-30-00.json\"\n",
    "\n",
    "if measure == 'taxi-availability':    \n",
    "    load_taxi_to_gbq(project=project,dataset_id=dataset_id,filename=filename,fs=None)\n",
    "else:\n",
    "    load_nea_to_gbq(project=project,dataset_id=dataset_id,measure=measure,filename=filename,fs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d203b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m92",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m92"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
