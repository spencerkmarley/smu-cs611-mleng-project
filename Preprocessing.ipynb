{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "To clean `JSON` weather and taxi avail files called from NEA and LTA sites <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ianchongweiming/smu-cs611-mleng-project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gcsfs\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from datetime import date, timedelta\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import joblib\n",
    "\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "from shapely import geometry\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from src import jsonParser\n",
    "from src import assignment\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "current_directory=os.getcwd()\n",
    "current_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing weather and taxi tabular files \n",
    "Merge the data together into 1 dataframe<br>\n",
    "This is only for ONE timestamp. Timestamps should be cleaned min is either 00 or 30; sec is 00<br>\n",
    "Eg 2019-01-01T12:30:00 <br>\n",
    "\n",
    "Weather files: <br>\n",
    "1. rainfall w stations value     ---   timestamp | station_id | value\n",
    "2. rainfall w stations latlon    ---  timestamp | station_id | latitude | longitude\n",
    "3. humidity w stations value     ---   timestamp | station_id | value\n",
    "4. humidity w stations latlon    ---   timestamp | station_id | latitude | longitude\n",
    "5. temperature w stations value  ---  timestamp | station_id | value\n",
    "6. temperature w stations latlon --- timestamp | station_id | latitude | longitude\n",
    "<br>\n",
    "\n",
    "Taxi files: <br>\n",
    "7. taxi avail json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'ml-eng-cs611-group-project'\n",
    "nea_bucket = 'ml-eng-cs611-group-project-nea'\n",
    "taxi_bucket = 'ml-eng-cs611-group-project-taxis'\n",
    "dataset_id='taxi_dataset'\n",
    "measure = 'rainfall'\n",
    "measures = ['rainfall','air-temperature','relative-humidity']\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project=project)\n",
    "nea_filenames = fs.glob('/'.join([nea_bucket,measure,\"*\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read grid file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_file = './updated codes/filter_grids_2/filter_grids_2.shp' ## To change directory\n",
    "\n",
    "grids = gpd.read_file(grids_file)\n",
    "grids['centroid'] = grids['geometry'].apply(lambda x: x.centroid) # get grids' centroid\n",
    "\n",
    "# convert to dataframe\n",
    "grids_df = pd.DataFrame(grids)\n",
    "grids_df['centroid'] = grids_df['centroid'].astype(str)\n",
    "grids_df['latlon'] = grids_df['centroid'].apply(lambda x: (float(x.split(' ')[1][1:]), float(x.split(' ')[2][:-1])))\n",
    "\n",
    "# Get unique grid_num\n",
    "grid_nums = list(grids_df['grid_num'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_num</th>\n",
       "      <th>intersect</th>\n",
       "      <th>geometry</th>\n",
       "      <th>centroid</th>\n",
       "      <th>latlon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.76364 1.47500, 103.78409 1.47500...</td>\n",
       "      <td>POINT (103.77386363636363 1.4647307692307692)</td>\n",
       "      <td>(103.77386363636363, 1.4647307692307692)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.78409 1.47500, 103.80455 1.47500...</td>\n",
       "      <td>POINT (103.79431818181817 1.464730769230769)</td>\n",
       "      <td>(103.79431818181817, 1.464730769230769)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.80455 1.47500, 103.82500 1.47500...</td>\n",
       "      <td>POINT (103.8147727272727 1.464730769230769)</td>\n",
       "      <td>(103.8147727272727, 1.464730769230769)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.82500 1.47500, 103.84545 1.47500...</td>\n",
       "      <td>POINT (103.83522727272724 1.464730769230769)</td>\n",
       "      <td>(103.83522727272724, 1.464730769230769)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.84545 1.47500, 103.86591 1.47500...</td>\n",
       "      <td>POINT (103.85568181818182 1.464730769230769)</td>\n",
       "      <td>(103.85568181818182, 1.464730769230769)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>255.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.84545 1.24908, 103.86591 1.24908...</td>\n",
       "      <td>POINT (103.85568181818182 1.2388076923076925)</td>\n",
       "      <td>(103.85568181818182, 1.2388076923076925)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>265.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.60000 1.22854, 103.62045 1.22854...</td>\n",
       "      <td>POINT (103.61022727272726 1.218269230769231)</td>\n",
       "      <td>(103.61022727272726, 1.218269230769231)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>266.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.62045 1.22854, 103.64091 1.22854...</td>\n",
       "      <td>POINT (103.6306818181818 1.2182692307692313)</td>\n",
       "      <td>(103.6306818181818, 1.2182692307692313)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>267.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.64091 1.22854, 103.66136 1.22854...</td>\n",
       "      <td>POINT (103.65113636363635 1.218269230769231)</td>\n",
       "      <td>(103.65113636363635, 1.218269230769231)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>268.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((103.66136 1.22854, 103.68182 1.22854...</td>\n",
       "      <td>POINT (103.67159090909091 1.2182692307692313)</td>\n",
       "      <td>(103.67159090909091, 1.2182692307692313)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     grid_num  intersect                                           geometry  \\\n",
       "0         9.0          1  POLYGON ((103.76364 1.47500, 103.78409 1.47500...   \n",
       "1        10.0          1  POLYGON ((103.78409 1.47500, 103.80455 1.47500...   \n",
       "2        11.0          1  POLYGON ((103.80455 1.47500, 103.82500 1.47500...   \n",
       "3        12.0          1  POLYGON ((103.82500 1.47500, 103.84545 1.47500...   \n",
       "4        13.0          1  POLYGON ((103.84545 1.47500, 103.86591 1.47500...   \n",
       "..        ...        ...                                                ...   \n",
       "176     255.0          1  POLYGON ((103.84545 1.24908, 103.86591 1.24908...   \n",
       "177     265.0          1  POLYGON ((103.60000 1.22854, 103.62045 1.22854...   \n",
       "178     266.0          1  POLYGON ((103.62045 1.22854, 103.64091 1.22854...   \n",
       "179     267.0          1  POLYGON ((103.64091 1.22854, 103.66136 1.22854...   \n",
       "180     268.0          1  POLYGON ((103.66136 1.22854, 103.68182 1.22854...   \n",
       "\n",
       "                                          centroid  \\\n",
       "0    POINT (103.77386363636363 1.4647307692307692)   \n",
       "1     POINT (103.79431818181817 1.464730769230769)   \n",
       "2      POINT (103.8147727272727 1.464730769230769)   \n",
       "3     POINT (103.83522727272724 1.464730769230769)   \n",
       "4     POINT (103.85568181818182 1.464730769230769)   \n",
       "..                                             ...   \n",
       "176  POINT (103.85568181818182 1.2388076923076925)   \n",
       "177   POINT (103.61022727272726 1.218269230769231)   \n",
       "178   POINT (103.6306818181818 1.2182692307692313)   \n",
       "179   POINT (103.65113636363635 1.218269230769231)   \n",
       "180  POINT (103.67159090909091 1.2182692307692313)   \n",
       "\n",
       "                                       latlon  \n",
       "0    (103.77386363636363, 1.4647307692307692)  \n",
       "1     (103.79431818181817, 1.464730769230769)  \n",
       "2      (103.8147727272727, 1.464730769230769)  \n",
       "3     (103.83522727272724, 1.464730769230769)  \n",
       "4     (103.85568181818182, 1.464730769230769)  \n",
       "..                                        ...  \n",
       "176  (103.85568181818182, 1.2388076923076925)  \n",
       "177   (103.61022727272726, 1.218269230769231)  \n",
       "178   (103.6306818181818, 1.2182692307692313)  \n",
       "179   (103.65113636363635, 1.218269230769231)  \n",
       "180  (103.67159090909091, 1.2182692307692313)  \n",
       "\n",
       "[181 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weather datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def query_nea_metadata(measure:str, query_timestamp:str, project_id='ml-eng-cs611-group-project',dataset_id='taxi_dataset_reference'):\n",
    "    '''Query NEA BigQuery for metadata\n",
    "    Args:\n",
    "        measure:            rainfall, relative-humidity or air-temperature\n",
    "        query_timestamp:    i.e. 2022-06-01 13:15:00\n",
    "        project_id:         Google Cloud project_id\n",
    "        dataset_id:         Google Cloud dataset_id\n",
    "    Returns:\n",
    "        pandas.DataFrame containing metadata for selected measure\n",
    "    '''\n",
    "    table_dict={'rainfall':'rainfall-metadata','relative-humidity':'relative-humidity-metadata','air-temperature':'air-temperature-metadata'}\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    SELECT timestamp, station, latitude, longitude\n",
    "    FROM `{dataset_id}.{table_dict[measure]}`\n",
    "    WHERE timestamp = '{query_timestamp}'\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.read_gbq(sql, project_id=project_id)\n",
    "\n",
    "\n",
    "def query_nea_items(measure:str, query_timestamp:str, project_id='ml-eng-cs611-group-project',dataset_id='taxi_dataset_reference'):\n",
    "    '''Query NEA BigQuery for metadata\n",
    "    Args:\n",
    "        measure:            rainfall, relative-humidity or air-temperature\n",
    "        query_timestamp:    i.e. 2022-06-01 13:15:00\n",
    "        project_id:         Google Cloud project_id\n",
    "        dataset_id:         Google Cloud dataset_id\n",
    "    Returns:\n",
    "        pandas.DataFrame containing metadata for selected measure\n",
    "    '''\n",
    "    table_dict={'rainfall':'rainfall-items','relative-humidity':'relative-humidity-items','air-temperature':'air-temperature-items'}\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    SELECT timestamp, station_id, value\n",
    "    FROM `{dataset_id}.{table_dict[measure]}`\n",
    "    WHERE timestamp = '{query_timestamp}'\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.read_gbq(sql, project_id=project_id)\n",
    "\n",
    "def query_nea_view(measure:str, query_timestamp:str, project_id='ml-eng-cs611-group-project',dataset_id='taxi_dataset_views'):\n",
    "    '''Query NEA BigQuery for metadata\n",
    "    Args:\n",
    "        measure:            rainfall, relative-humidity or air-temperature\n",
    "        query_timestamp:    i.e. 2022-06-01 13:15:00\n",
    "        project_id:         Google Cloud project_id\n",
    "        dataset_id:         Google Cloud dataset_id\n",
    "    Returns:\n",
    "        pandas.DataFrame containing metadata for selected measure\n",
    "    '''\n",
    "    table_dict={'rainfall':'view-rainfall','relative-humidity':'view-relative-humidity','air-temperature':'view-air-temperature'}\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `{dataset_id}.{table_dict[measure]}`\n",
    "    WHERE timestamp = '{query_timestamp}'\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.read_gbq(sql, project_id=project_id)\n",
    "\n",
    "def assign_grids(grids_df, df_metadata, df_items, grid_nums):\n",
    "    '''\n",
    "    Arguments\n",
    "    grids_df: dataframe that contains grid numbers and their centroid latlon    \n",
    "    df_metadata: dataframe with station metadata i.e. latitude and longitude\n",
    "    df_: dataframe that contains stn latlon\n",
    "    ts: timestamp\n",
    "    grid_nums: list of unique grid numbers\n",
    "    '''\n",
    "    \n",
    "    df_metadata['latlon']=df_metadata[['longitude','latitude',]].apply(tuple,axis=1)\n",
    "    df_metadata.index=df_metadata['station']\n",
    "    assignment={}\n",
    "\n",
    "    for i in range(len(grid_nums)): # for each grid_num\n",
    "        grid_coordinates = grids_df.iloc[i]['latlon'] # latlon of row i grid_num        \n",
    "        distances = df_metadata['latlon'].apply(lambda x: distance.euclidean(x,grid_coordinates))\n",
    "        distance_sorted = distances.sort_values()\n",
    "        \n",
    "        for station in distance_sorted.index:\n",
    "            if any(df_items[df_items['station_id']==station]): # there is a value                \n",
    "                assignment[i]=station\n",
    "                break\n",
    "        \n",
    "            else:\n",
    "                continue           \n",
    "    \n",
    "    return assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air-temperature</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>relative-humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S100</td>\n",
       "      <td>S104</td>\n",
       "      <td>S100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S100</td>\n",
       "      <td>S104</td>\n",
       "      <td>S100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S100</td>\n",
       "      <td>S227</td>\n",
       "      <td>S100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S100</td>\n",
       "      <td>S227</td>\n",
       "      <td>S100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S100</td>\n",
       "      <td>S209</td>\n",
       "      <td>S100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>S108</td>\n",
       "      <td>S108</td>\n",
       "      <td>S108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>S121</td>\n",
       "      <td>S115</td>\n",
       "      <td>S121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>S121</td>\n",
       "      <td>S115</td>\n",
       "      <td>S121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>S121</td>\n",
       "      <td>S115</td>\n",
       "      <td>S121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>S121</td>\n",
       "      <td>S115</td>\n",
       "      <td>S121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    air-temperature rainfall relative-humidity\n",
       "0              S100     S104              S100\n",
       "1              S100     S104              S100\n",
       "2              S100     S227              S100\n",
       "3              S100     S227              S100\n",
       "4              S100     S209              S100\n",
       "..              ...      ...               ...\n",
       "176            S108     S108              S108\n",
       "177            S121     S115              S121\n",
       "178            S121     S115              S121\n",
       "179            S121     S115              S121\n",
       "180            S121     S115              S121\n",
       "\n",
       "[181 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_timestamp = '2022-06-01 13:15:00'\n",
    "measures = ['air-temperature','rainfall','relative-humidity']\n",
    "assignment = {measure:[] for measure in measures}\n",
    "for measure in measures:\n",
    "    df_metadata=query_nea_metadata(measure=measure,query_timestamp=query_timestamp)\n",
    "    df_items=query_nea_items(measure=measure,query_timestamp=query_timestamp)\n",
    "    result=assign_grids(grids_df,df_metadata,df_items,grid_nums)\n",
    "    assignment[measure]=result\n",
    "\n",
    "assignment_df=pd.DataFrame(assignment)\n",
    "assignment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing weather files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load taxi json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'taxi_avail.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27096/3828007133.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtaxi_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'taxi_avail.joblib'\u001b[0m \u001b[0;31m# change directory and extension of file accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtaxi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaxi_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# change reading method according to the file type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'taxi_avail.joblib'"
     ]
    }
   ],
   "source": [
    "taxi_file = 'taxi_avail.joblib' # change directory and extension of file accordingly\n",
    "taxi = joblib.load(taxi_file) # change reading method according to the file type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing taxi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of taxi's coord\n",
    "one_list = taxi['features'][0]['geometry']['coordinates']\n",
    "# Convert list to corr grid num of the coord\n",
    "test = [math.ceil((i[0]-103.6)/0.020454545454545583) + (13 - math.ceil((i[1] -1.208)/0.020538461538461547))*22 for i in one_list]\n",
    "\n",
    "# getting dictionary of items\n",
    "c = Counter(test)\n",
    "\n",
    "# Getting taxi_count for relevant grid_num\n",
    "df_taxicount = pd.DataFrame({'grid_num': [float(x) for x in list(c.keys())], \n",
    "                             'taxi_count': [x[1] for x in list(c.items())]})\n",
    "\n",
    "# Get full list of grid_num as a dataframe:  grid_num | timestamp\n",
    "all_grids = grids[['grid_num']]\n",
    "all_grids['timestamp'] = ts\n",
    "\n",
    "\n",
    "# Merge all_grids and df_taxicount\n",
    "taxi_clean = pd.merge(all_grids, df_taxicount, how='left')\n",
    "taxi_clean['taxi_count'] = taxi_clean['taxi_count'].fillna(0) #fill missing taxi_count = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merging all the cleaned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge all together\n",
    "merge_df = pd.merge(humid_clean, rain_clean)\n",
    "merge_df = pd.merge(merge_df, temp_clean)\n",
    "merge_df = pd.merge(merge_df, taxi_clean)\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df['timestamp'] = merge_df['timestamp'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S'))\n",
    "merge_df['hour'] = merge_df['timestamp'].apply(lambda x: x.hour)\n",
    "merge_df['month'] = merge_df['timestamp'].apply(lambda x: x.month)\n",
    "merge_df['day'] = merge_df['timestamp'].apply(lambda x: x.weekday())\n",
    "merge_df['minute'] = merge_df['timestamp'].apply(lambda x: x.minute)\n",
    "\n",
    "merge_df['time_30'] = merge_df['timestamp'].apply(lambda x: x + timedelta(hours=0.5))\n",
    "merge_df['time_60'] = merge_df['timestamp'].apply(lambda x: x + timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To get y_30 and y_60 targets\n",
    "# for each timestamp, get 30min later\n",
    "merge_df['y_30'] = np.nan\n",
    "merge_df['y_60'] = np.nan\n",
    "\n",
    "for i in tqdm(range(len(merge_df))): # for each row\n",
    "    ts = merge_df.iloc[i]['time_30']\n",
    "    gridnum = merge_df.iloc[i]['grid_num']\n",
    "    \n",
    "    merge_df.iloc[i, merge_df.columns.get_loc('y_30')] = merge_df[(merge_df['grid_num'] == gridnum) & \n",
    "                                                                       (merge_df['timestamp'] == ts)].reset_index()['taxi_count'][0]\n",
    "    \n",
    "\n",
    "for i in tqdm(range(len(merge_df))): # for each row\n",
    "    ts = merge_df.iloc[i]['time_60']\n",
    "    gridnum = merge_df.iloc[i]['grid_num']\n",
    "    \n",
    "    merge_df.iloc[i, merge_df.columns.get_loc('y_60')] = merge_df[(merge_df['grid_num'] == gridnum) & \n",
    "                                                                       (merge_df['timestamp'] == ts)].reset_index()['taxi_count'][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge_df is the final dataset, ready to be used for EDA/ training etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m92",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m92"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
